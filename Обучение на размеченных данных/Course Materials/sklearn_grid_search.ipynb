{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ pandas 0.23.4\n",
    "+ numpy 1.15.4\n",
    "+ sklearn 0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "документация: http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, datasets, linear_model, metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(iris.data, iris.target, \n",
    "                                                                                     test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1,\n",
       "       2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0,\n",
       "       2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1,\n",
       "       1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.SGDClassifier(random_state = 0, tol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'loss' : ['hinge', 'log', 'squared_hinge', 'squared_loss'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'max_iter' : np.arange(5,10),\n",
    "    'alpha' : np.linspace(0.0001, 0.001, num = 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.StratifiedShuffleSplit(n_splits=10, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 s, sys: 85.3 ms, total: 4.16 s\n",
      "Wall time: 4.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
       "       tol=0.001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'loss': ['hinge', 'log', 'squared_hinge', 'squared_loss'], 'penalty': ['l1', 'l2'], 'max_iter': array([5, 6, 7, 8, 9]), 'alpha': array([0.0001 , 0.00032, 0.00055, 0.00078, 0.001  ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=9, n_iter=None,\n",
       "       n_jobs=1, penalty='l1', power_t=0.5, random_state=0, shuffle=True,\n",
       "       tol=0.001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8523809523809524\n",
      "{'alpha': 0.001, 'loss': 'log', 'max_iter': 9, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv.best_score_)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannalaurynovich/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.75238, std: 0.12381, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       " mean: 0.71429, std: 0.15793, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       " mean: 0.74762, std: 0.12056, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       " mean: 0.71905, std: 0.15858, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       " mean: 0.75238, std: 0.12381, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       " mean: 0.71905, std: 0.15858, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       " mean: 0.75238, std: 0.12381, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       " mean: 0.71905, std: 0.15858, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       " mean: 0.75238, std: 0.12381, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       " mean: 0.71905, std: 0.15858, params: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l2'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.grid_scores_[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_grid_cv = model_selection.RandomizedSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv, n_iter = 20, \n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 419 ms, sys: 8.43 ms, total: 427 ms\n",
      "Wall time: 431 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "          error_score='raise',\n",
       "          estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
       "       tol=0.001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=1,\n",
       "          param_distributions={'loss': ['hinge', 'log', 'squared_hinge', 'squared_loss'], 'penalty': ['l1', 'l2'], 'max_iter': array([5, 6, 7, 8, 9]), 'alpha': array([0.0001 , 0.00032, 0.00055, 0.00078, 0.001  ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "randomized_grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819047619047619\n",
      "{'penalty': 'l1', 'max_iter': 5, 'loss': 'squared_hinge', 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(randomized_grid_cv.best_score_)\n",
    "print(randomized_grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-16 11:14:39\n",
      "Control sum: 949\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def control_sum(str):\n",
    "    return sum(map(ord, list(str)))\n",
    "\n",
    "\n",
    "def check(reply):\n",
    "    def _is_number(str):\n",
    "        try:\n",
    "            int(str)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    if \"Control sum:\" not in reply:\n",
    "        return False\n",
    "    parts = reply.split(\"Control sum:\")\n",
    "    received_current_time = parts[0].strip()\n",
    "    received_control_sum = parts[1].strip()\n",
    "    if not _is_number(received_control_sum):\n",
    "        return False\n",
    "    else:\n",
    "        received_control_sum = int(received_control_sum)\n",
    "    expected_control_sum = control_sum(received_current_time)\n",
    "    return expected_control_sum == received_control_sum\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(current_time)\n",
    "print(\"Control sum: \" + str(control_sum(current_time)))\n",
    "\n",
    "#print check(current_time + '\\n' + \"Control sum: \" + str(control_sum(current_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
